# Gotutiyanの論文メモ

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax:{inlineMath:[['\$','\$'],['\\(','\\)']],processEscapes:true},CommonHTML: {matchFontHeight:false}});</script>
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>

# [GECToR – Grammatical Error Correction: Tag, Not Rewrite](https://aclanthology.org/2020.bea-1.16) (Omelianchuk et al., BEA 2020)

- Grammarlyのチーム
- 系列タグ付け（トークン単位の分類器）で教師あり設定の文法誤り訂正
- 入力：誤りを含む可能性のある文
- 出力：編集情報を示すタグ（実際にはその後タグを入力に反映し，訂正文を得るが，それはあくまで後処理）．
- タグは次の2種類
  - basic-transformation: 置換・挿入・削除・無編集の4種類に基づく．
  - g-transformation: 言語情報を考慮．「名詞を単数形に」とか，「動詞には過去形に」とか．
- 学習時は，タグの推定と単語レベルの誤り検出をマルチタスクで解く．
- 推論時は，複数サイクル訂正することで複数単語の挿入などの訂正を実現．訂正にはタグのみが使われ，サイクルをどこまで回すかに誤り検出の情報が使われる．
- 実験
  - 学習時には3段階の訓練．
  - 推論時は2回のサイクルを回せば大半の訂正は処理できる
  - エンコーダはRoBERTaとかXLNetを使っておけば良さそう
  - アンサンブルは効果あり，ベンチマークで2ポイント程度向上
- 感想：分類器のクラスを考えると，訂正しないときのタグは一つに集約されるが，訂正のタグは様々にあるのでラベルはすごく不均衡．でも誤り検出タスクでは訂正側のラベルも一つに集約されているとみなせるので，誤り検出を学習しているのが上手くいくキモ？

# [Language-agnostic Representation from Multilingual Sentence Encoders for Cross-lingual Similarity Estimation](https://aclanthology.org/2021.emnlp-main.612) (Tiyajamorn et al., EMNLP 2021)

- mBERTなどによる多言語文埋め込みを，意味情報の埋め込みと言語情報の埋め込みに分離する方法を提案．異なる言語間で意味類似性を正確に計算することが動機．

- 提案法では，翻訳のデータが（i）文対は異なる言語・同じ意味，（ii）原言語側もしくは目的言語側のみでは同じ言語・異なる意味，である性質を利用．

- 既存の文埋め込みを2種類の線形層に独立に通して，それぞれの出力が意味情報と言語情報を表すのだと思うことにする：

  $e = \mathrm{Encoder}(x)$

  $\hat{e}_M = \mathrm{MLP}_M(e)$

  $\hat{e}_L = \mathrm{MLP}_L(e)$．

- 学習時の損失は3種類．

  - Reconstruction loss: 両者を足せば元の埋め込みに戻る．
  - Language loss: 言語情報の埋め込みについて，同じ言語で異なる文同士の類似度が高くなるようにする．また，言語判定ができるようにする．
  - Meaning loss: 意味情報の埋め込みについて，文対間では類似度が高くなり，同じ言語で異なる文同士の類似度は低くなるようにする．

- 推論時に意味類似性を計算するときには，意味情報の空間で単にコサイン類似度を考えればいい．

- 実験では翻訳の品質推定タスク（WMT20 QE）と多言語の意味類似性を測定するタスク（SemEval-2017 Cross-lingual STS）を実施．多くの場合で，意味と言語を分離したほうが意味類似性を正確に計算できた．

- 感想：実装が楽だし，直感的にも上手くいきそうな手法に感じた．意味情報を正確に獲得するために言語情報を別の空間に追い出しているようなイメージなので，他のタスクでも埋め込みから"追い出したいもの"があれば使えそう．

# [Adjusting the Precision-Recall Trade-Off with Align-and-Predict Decoding for Grammatical Error Correction](https://aclanthology.org/2022.acl-short.77) (Sun & Wang, ACL 2022)

- 自己回帰モデルの推論時に，どれくらい書き換えを促進するかを制御する手法を提案．
- 提案法では，生成の途中で逐次的に入力文とのアライメントを取る．アライメントを取れば，現段階で入力文に対応する出力がどこまで生成できているかが分かるため，次にどの単語を生成すれば入力文のコピーになるかも分かる．コピーになる単語の生成確率を意図的に上げる・下げることで，積極的な書き換えを制御・促進する．
- ※アライメントとは言うが，生成途中系列の末尾部分についてわかればいいので，アライメントを全て求める必要はない．実装上は，keyにn-gram，valueにそのn-gramの次のトークンを格納する辞書を事前に構築することで高速に計算．
- ※論文の式4はlogの確率になっているため，式5で導入されている重み$\lambda$の解釈に注意．
- 実験では英語と中国語の文法誤り訂正を行い，$\lambda$の値によって訂正の積極性が制御されていることを確認．これはPrecisionとRecallを制御可能ということでもある．$\lambda=0.5$付近が良い感じらしい．
- 感想：推論時の手法なので，導入コストが低いのが良い．また任意の自己回帰モデルに利用できる．書き換えの積極性と訂正文の流暢性の関係は気になる．

# [Grammatical Error Correction: Are We There Yet?](https://aclanthology.org/2022.coling-1.246) (Qorib & Ng, COLING 2022)

- 現状の文法誤り訂正システムに存在する課題を分析した論文．
- 分析の対象のモデルは，T5ベース（自己回帰）とGECToR（非自己回帰）
- 以下の観点で課題があるとしている．
  - 不自然な表現の訂正．既存の訓練データは最小限に訂正されていることが主な原因．
  - 文構造の認識．主語や目的語が複合語句になっているときに失敗しがち．
  - 文の理解．書き手の意図を反映した訂正は難しい．
  - 誤り率が高い文の訂正．
  - 長い文の訂正．
  - 文脈を考慮した訂正．多くのモデルは単文の訂正にとどまる．
  - 異なるドメインへの適応．
- 以上の観察から，以上の項目を明示的に含んだような評価データが必要であると主張．
- 感想：文法誤り訂正分野の課題を実例も交えて真正面から指摘した点が貢献．論文では評価データの重要性のみ言及されていたが，解けないことを測定すると同時に解けるようにすることも必要なので，訓練データの整備も考えないとな，という気持ちに．

# [BLEURT: Learning Robust Metrics for Text Generation](https://aclanthology.org/2020.acl-main.704) (Sellam et al., ACL 2020)

- ニューラル（BERT）ベースのロバストな言語生成の評価尺度を作成．
- システム出力は日々変化するため，古いデータで学習された評価器はそれ以降のシステム出力を正しく評価できない可能性がある．
  - 重要なのはドメインや品質の観点で外挿が可能であること．
- 提案法では，ロバストな評価器を構築するためにWikipediaを元データとする擬似データによる訓練を実施．まず，マスクトークンの復元・逆翻訳・単語の削除により擬似的なシステム出力を作成する．この擬似出力文と参照文（元データ）からBLEUやBERTScoreなどの多様な評価尺度で評価値を計算しておく．事前訓練ではそれらの値を直接予測できるように評価器を訓練する．
- WMT17,18,19の評価タスクで実験．多くの場合で提案法が既存手法よりも人手評価との高い相関を達成．つまり，訓練よりも評価データが新しいものになってもロバストに評価可能．
- また，WMT17の評価タスクにおいて，品質が悪いものを訓練に，品質が高いものを評価に意図的におくような設定で実験．擬似データによる事前訓練をしたほうが，人手評価との高い相関を達成．つまり，事前訓練を行うことで，訓練と評価の品質が大きく異なってもロバストに評価可能．
- WebNLG Challenge 2017のタスクの評価についても実験．WebNLGのデータを使わずとも既存手法を上回る結果に．つまり，訓練と評価のドメインが異なっていてもロバストに評価可能．
- 事前訓練では多様な尺度を目的関数に事前訓練するが，BLEUとROUGEは悪影響であることを示唆．
- 感想：言語生成の評価のための事前訓練として，多様な評価尺度に直接最適化するのが有効である，という点が面白かった．事前学習時に各タスクがどれくらい学習可能なのかという点は気になった（各事前学習タスクについて，5.4のablation studyにおける影響と，学習の易しさみたいなものが関係している気もした）．

# [Revisiting Grammatical Error Correction Evaluation and Beyond](https://aclanthology.org/2022.emnlp-main.463) (Gong et al., EMNLP 2022)

- 文法誤り訂正の参照あり評価尺度として，PT-M2を提案．従来のスパン一致ベースの枠組みと，BERTScoreなどのPretraining-based（PT-based）なスコアを組み合わせた．
- BERTScoreのようなPT-basedな尺度は多くのタスクで使われつつあるが，文法誤り訂正では使われていない．
  - 実際に使ってみると，文法誤り訂正特有の性質「多くの単語は変化しないこと」が原因で，スコアを正確に計算できないと主張．
- 提案法では，既存のスパンの一致に基づく参照あり評価において，スパンの重みをPT-basedな尺度で計算し，重み付きのprecision, recall, F0.5を考える．
  - 具体的には，入力文$S$，参照文$R$，入力に何らかの訂正ただ一つを加えた文$S'$を用いて$w=\mathrm{PTScore}(S', R) - \mathrm{PTScore}(S, R)$で計算する．$\mathrm{PTScore}(\cdot)$にはBERTScoreなどを利用できる．
  - $w$は絶対値をとる．（以下は自分の意見）一見，訂正が悪いことを示す$w<0$の場合にも，絶対値を取ることで正の評価を与えてしまうように思える．しかし，正解データに含まれる訂正で$w<0$になる訂正は非常に少ないと考えられるため，実用上問題ないと思う．（モデルが$w$が大きく負になるような悪い訂正をしても，そのような訂正は通常正解データにないのでPrecisionの分母がすごく大きくなるだけ）
- 実験ではCoNLL-14の参加システムの人手ランキング結果との相関について，提案法が従来の参照あり尺度およびPT-basedな尺度を上回ることを報告．
- 分析："良いこと"を判別する能力に長ける．"悪いこと"を評価するのは少し難あり．PT-basedな尺度のためのエンコーダのモデルサイズは，Base相当で十分で，特に大きいものを使う必要はない．
- 感想：ありそうでなかった評価尺度で，参照ありの尺度でありながらも人手評価との高く相関することが魅力．一方，分析はほぼ相関が高い・低いの話をしているが，もう少し他の観点からの話題も欲しい．例えば，どのようなことを評価するために使えるのか，評価結果からどのような分析につながるか，といったユースケースの点．もしくは，なぜ提案法は人手評価と高く相関するのか，という点も考察を与えて欲しい．多分，PT-basedな手法は内容語に敏感に反応して機能語はそんなに，みたいな傾向がある気がしていて，その傾向と人間が訂正結果の質を判断するときの傾向が似ている，みたいな話がある気がする．

# [Is this the end of the gold standard? A straightforward reference-less grammatical error correction metric](https://aclanthology.org/2021.emnlp-main.239) (Islam & Magnani, EMNLP 2021)

- 文法誤り訂正のための参照なし評価尺度としてScribendi Scoreを提案．

- 提案法の入力は誤り文(src)と訂正文(pred)．出力は訂正文の評価値であり，-1, 0, 1のいずれかの整数値．

- 評価のアルゴリズムは2段階．論文にもある擬似コードが分かりやすい．

  - perplexityの計算は適当な言語モデルを使う
  - token sort ratioは，単語を入れ替える訂正がある場合に正しく意味保存性を測定する狙い．
  - levenshtein distance ratioは文字レベルの編集距離を使う．この値がある程度高ければ，srcの意味が保持されていると思うことにする．

  ```python
  def Scribendi_score(src, pred):
  	if pred == src:
  		return 0 # 同じなら0
  	if perplexity(src) <= perplexity(pred):
  		return -1 # perplexityについてpredの方が悪ければ-1
  	else:
      trs = token_sort_ratio(src, pred)
      ldr = lev_dist_ratio(src, pred) # 文字レベル編集距離
      if max(trs, ldr) >= 0.8:
        return 1
      else:
        return -1
  ```

- 実験では，CoNLL-14の参加システムの人手ランキング結果と高く相関することを確認．参照なし評価尺度の既存手法であるSOMEには若干劣るが，SOMEと異なり特別な人手評価データを必要としていない．
- また，提案法は同じ単語の繰り返しになっているpredictionをちゃんと"悪い"と評価できる．SOMEはそのようなpredictionについて高い評価を与えてしまう．
- 感想：人手評価との相関が高く，実装も簡単なので使いやすい尺度だと感じた．評価のアルゴリズムは，まず流暢性で足切りし，その後意味保存性を見ているともみなせる．-1が返るタイミングは2回あるため，どちらのタイミングかまで見ることで，システムの課題が流暢性もしくは意味保存性のどちらにあるのか分析可能かもしれない．

# [Grammatical Error Correction with Contrastive Learning in Low Error Density Domains](https://aclanthology.org/2021.findings-emnlp.419) (Cao et al., Findings 2021)

- 教師ありの文法誤り訂正において，Low Error Density Domain（含まれる誤りが少ないドメイン）のための対照学習手法を提案．
- 提案法は2段階の学習．1段階目はBEA-trainを用いた通常ドメインの学習，2段階目でLow Error Density Domainデータを用いた対照学習．
- 対照学習における目的関数は，通常の自己回帰モデルの損失関数$L_{NLL}$と，対照学習の提案損失関数$L_{CL} = \max (-\log P(\mathrm{positiveサンプルの}y|x) + \log P(\mathrm{negativeサンプルの}y|x), 0))$の足し算の形．
- positive sampleには訓練データ$<s_i, t_i>$を使う．negative sampleには次の2つの戦略を用いる．
  - $\mathrm{CL}^-$： 1段階目の学習結果の重みによるk-best出力でターゲットを置き換えたものをnegativeに
  - $\mathrm{CL}$：$\mathrm{CL}^-$に加えて$s_i \neq t_i$の時に$<s_i, s_i>$をnegativeに
- 実験では，ネイティブドメイン（誤りの数が少ない）の評価データCWEBで実験し，性能向上を確認．
- 分析では，negative samplingにおける2つ目の戦略（$<s_i, s_i>$）がprecisionとrecallの両方を向上させる効果を持つ．また，対照学習によって過剰な訂正と不十分な訂正の両方を低減できる．
- 感想：Contrastive learningの枠組みを文法誤り訂正に適用したのは新しい．一方，研究目的はLow Error Density Domainにおける訂正性能を向上させることだが，ドメイン関係なく単に訂正性能が向上しただけのようにも見える．CWEBとCWEB以外の評価データで性能の変化を比較した時に，CWEBで特に向上していれば有効だと言えそう？

# [Controlling Grammatical Error Correction Using Word Edit Rate](https://aclanthology.org/P19-2020) (Hotate et al., ACL 2019)

- 教師ありの文法誤り訂正において，推論時に訂正の度合いを制御できるような学習手法を提案．
- 提案法では，source-target間の単語レベル編集率（WER, Word Edit Rate）に基づいて<1>（訂正が保守的である）から<5>（訂正が積極的である）までの記号をsourceの先頭に付与する．そのデータを用いて通常の自己回帰モデルの枠組みで学習する．
- 推論時には，所望の訂正の度合いに応じて<1>から<5>までのいずれかの記号をsourceに付与して入力する．

- 実験では，WERの記号によって実際に訂正の度合いを制御できることを確認．また，同じ入力でも<1>から<4>に変化させることで，高Precision低Recallから低Precision高Recallになり，PrecisionとRecallの重要度の観点からも制御可能．<5>は訓練データにノイズが多く，うまくいかない．
- ある入力文に<1>から<5>の記号を順に付与して生成することにより多様な5-bestの訂正文が得られる．これらのうちオラクルWERで評価すると，ベースラインを大幅に上回る．実際には，そのようなオラクルをリランキングで持ってくるのは難しい．また，意図的に評価データの文対から計算したWER（Gold WER）はオラクルWERとは異なっていて性能が出ない．
- 提案法により訓練されたモデルは，推論時に与えたWERよりも少ない度合いで訂正する傾向がある．
- 感想：先頭に特殊記号を付与するシンプルな手法なので使いやすそう．やはり適切なWERを推定するのは難しいという問題はあるので，Encoder側でWERの記号を推定させるマルチタスクで解いてみるのも面白そう．

# [Instantaneous Grammatical Error Correction with Shallow Aggressive Decoding](https://aclanthology.org/2021.acl-long.462) (Sun et al., ACL-IJCNLP 2021)

- 教師ありの文法誤り訂正モデルとして，自己回帰モデルと非自己回帰モデルを組み合わせたShallow Aggressive Decoding (SAD) を提案．
- 提案法は非自己回帰→自己回帰→非自己回帰→....のように2種類の生成方法を交互に適用して訂正文を生成．入力のコピーとなる生成を非自己回帰が，書き換えとなる生成を自己回帰が担う．
  - 初回の非自己回帰による生成で入力と同じ文が生成されたら誤りがないと判断し終了．そうでない時，先頭から見て最初に入力文とは異なる部分を見つけて，そこからは自己回帰で生成．自己回帰で生成する中で再度入力と同じ系列を生成するようになれば，その先を非自己回帰で生成...を繰り返し適用．
- また，速度の向上を目的としてデコーダの層を浅くすることも実施．予備実験によりエンコーダを9層，デコーダを3層にするのが高性能（速度も1.8倍）．
- 英語での実験では，提案法によって速度はベースラインの10倍，訂正性能も向上．中国語でも実験を行い，性能を維持したまま速度が12倍．以上から，言語非依存で効果がある手法であることを主張．
- 速度について，より大きな編集が必要な文であるほど，自己回帰の仕事が多くなるため遅くなる．
- 感想：コピーできるところは一気に生成してしまうことで速度を上げているのが面白いし，目的と手法がちゃんと一致しているように感じた．気になる点があるとすれば，書き換えが必要なところは自己回帰モデルに完全に任せる手法だが，実際には非自己回帰モデルも何かしら生成しているわけで，その結果もうまく使えないかな，とは思った．その辺り，自己回帰モデルと非自己回帰モデルの訂正傾向の違いが分かれば，両者の出力をうまく使う方法論が確立できるかもしれない．

# [Type-Driven Multi-Turn Corrections for Grammatical Error Correction](https://aclanthology.org/2022.findings-acl.254) (Lai et al., Findings 2022)

- 系列タグ付けベースの教師あり文法誤り訂正において，誤りの依存関係を考慮した訂正，および訓練時と推論時のギャップを埋めるためにType-Driven Multi-Turn Corrections (TMTC)を提案．
  - 訓練時には一度のみ訂正するように学習するが，推論時には複数回の反復的な訂正を行うというギャップ．
- 提案法では既存の訓練データに含まれる誤り文$X_e$と訂正文$X_c$のペアに対する中間文$X'$を考え，「$X_e → X'$」および「$X'$→$X_c$」のように段階的な訂正を行うデータを構築する．$X'$は，挿入・置換・削除の種類のうちいずれかの種類のみを手動で適用することで作成．
- ただし，「$X_e→X'$」の学習においては，挿入・置換・削除のうち2種類の誤りは訂正されずに残るため，モデルが多くの誤りを訂正しないように学習してしまう．これを防ぐため，$X_e→X'$のためのタグと，元の訓練データである$X_e→X_c$のためのタグが一致しているようなトークンにのみ損失を流す（論文中の式3）．
- 実験では，提案法をGECToRに適用し，性能が向上することを確認．
- 分析:
  - $X'$を作るために選んだ編集操作（挿入・置換・削除）が，一度目の訂正時により多く出力されることを確認（データの作り方がちゃんと学習に影響を与えている）．
  - $X'$の時点で適用されている誤りが多いほど低Precission高Recallになる．（学習時のKEEPタグが減るから？）
  - 中間文を増やすことも考えられる（$X_e→X'→X''→X_c$みたいな）が，増やしても特に性能はほぼ伸びないか低下するので，1つで十分．

- 感想：学習時と推論時のギャップについては同じことを思っていたので参考になった．気になる点としては，$X'$を編集操作ごとにグルーピングして作成している点で，本当にこれでギャップが埋まっているのかは疑問．例えば，同じ隙間に複数トークンを追加するときは挿入操作を反復的にやる必要があり，$X'$には挿入途中の状況を再現するべき．一方，提案法ではそのような$X'$を作れない．

# [Competence-based Curriculum Learning for Neural Machine Translation](https://aclanthology.org/N19-1119) (Platanios et al., NAACL 2019)

-  教師あり機械翻訳のためのカリキュラム学習手法としてCompetence-based Curriculum Learningを提案．
- 提案法は，DifficultyとCompetenceの2つのパラメータを主軸とする． 
  - Difficultyは，何らかの方法で訓練データの各サンプルの難易度を決めて，難易度の昇順でソートし，その累積密度関数上の値として定義する．
  - Competenceは，学習のタイムステップ$t$の関数として定義する（学習率のスケジューラみたいなイメージ）．
  - DifficultyとCompetenceは共に，値域を[0,1]となるようにする．学習の流れとしては，ステップが進むにつれてCompetenceを更新し（増加させ），Competence以下のDifficultyである事例からミニバッチをサンプルする．
  - 例えば，5つの学習データのDifficultyが`[1,1,4,4,5]`だとすると， そのDifficultyは`[0.06, 0.13, 0.40, 0.66, 1]`となる．またタイムステップ$1\leq t \leq 5$の範囲で，Competenceを雑に$competence=0.2t$とかに設定するならば，最初のタイムステップには`0.2`以下のdifficultyのサンプル（先頭から2つ分）が使われ，次には`0.4`以下のdifficultyのサンプル（先頭から3つ分）が使われ...，という具合．
- 各サンプルに対するDifficultyの定義には，単語のレア度や文長のどちらかを使用．（レアな単語が使われているほど難しい / 長い文であるほど難しい）
- Competenceの関数はいくつか定義しているが，実験結果で最も性能が良かったのは式8の$c_{sqrt} (t) \triangleq \min(1, \sqrt[2]{t\frac{1-c_0^2}{T} + c_0^2})$．$c_0$はcompetenceの初期値で，$T$は最大タイムステップ数．
- 実験では，WMT16 en-deなどの翻訳データについて，RNNおよびTransformerのモデルで実験．提案法により，BLEUスコアが2ポイント程度向上すること，学習速度が70%程度速くなることを確認．RNNよりもTransformerの方が効果が高い．
- 上の実験においてTransformerは学習率のスケジューラを用いていないのに高性能なため，提案法が学習率スケジューラを代替したのでは，という仮説のもとで追加実験．実際に提案法はスケジューラを導入するよりも短い学習時間で性能向上に大きく寄与することを確認．
- 感想：提案法はアーキテクチャ非依存なため，任意のアーキテクチャに適用可能．また，難易度もタスクに応じて自由に決めていいので，翻訳以外のタスクにも容易に適用できるのが嬉しい．提案法のように連続的にデータを増やしていくカリキュラム学習では，特に難しい事例がミニバッチにサンプルされる機会が著しく少なくなる問題がある気はするが，そこは案外問題ないのだろうか．

